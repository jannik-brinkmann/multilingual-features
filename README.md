# Large Language Models Share Representations of Latent Grammatical Concepts Across Typologically Diverse Languages
 
## Resources
- [Aya-23-8B](https://huggingface.co/jbrinkma/sae-aya-23-8b-layer16) and [Llama-3-8B](https://huggingface.co/jbrinkma/sae-llama-3-8b-layer16) sparse autoencoders
- [Universal Dependencies](https://universaldependencies.org)

## Citation
If you use any of the code or ideas presented here, please cite our paper:
```bibtex
@misc{brinkmann2025largelanguagemodelsshare,
      title={Large Language Models Share Representations of Latent Grammatical Concepts Across Typologically Diverse Languages}, 
      author={Jannik Brinkmann and Chris Wendler and Christian Bartelt and Aaron Mueller},
      year={2025},
      eprint={2501.06346},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.06346}, 
}
```


If you use the dataset, please also cite: 
```bibtex
@inproceedings{arora-etal-2024-causalgym,
    title = "{C}ausal{G}ym: Benchmarking causal interpretability methods on linguistic tasks",
    author = "Arora, Aryaman and Jurafsky, Dan and Potts, Christopher",
    editor = "Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.785",
    doi = "10.18653/v1/2024.acl-long.785",
    pages = "14638--14663"
}
```

